# MCGA: A Multi-task Classical Chinese Literary Genre Audio Corpus
MCGA (Multi-task Classical Chinese Literary Genre Audio Corpus) is the first large-scale, open-source, and fully copyrighted audio corpus dedicated to Classical Chinese Studies, comprising 119 hours (22,000 samples) of standard Mandarin recordings by native speakers that span five major literary genres (Fu, Shi, Wen, Ci, and Qu) across 11 historical periods, specifically constructed to support six core speech-centric tasksAutomatic Speech Recognition (ASR), Speech-to-Text Translation (S2TT), Speech Emotion Captioning(SEC), Spoken Question Answering(SQA), Speech Understanding(SU), Speech Reasoning(SR) to bridge the gap in domain-specific audio resources and advance the multidimensional capabilities of Multimodal Large Language Models.
- **Language**: Mandarin Chinese
- **Data Size**: 22,000 sample, 119hour
- **Data Split**: Train / Val / Test
- **Data Source**: Native speakers (13 males and 15 females)
- **Domain**: Classical Chinese Literary Study
- **Literary Genre**: Fu (Rhapsody), Shi (Poetry), Wen (Prose), Ci (Lyric), and Qu (Song)
- **Task**: ASR, S2TT, SEC, SQA, SU, SR
- **License**: CC BY-NC-SA-4.0

> **Note:** The **Test split** is released first for fair benchmarking.
> The full dataset will be available soon.

ğŸ“„Paperï¼š[https://arxiv.org/abs/2601.09270](https://arxiv.org/abs/2601.09270)

## How to use
```python
from datasets import load_dataset
MCGA = load_dataset("yxdu/MCGA")
print(MCGA)
```


## Installation
```
git clone https://github.com/yxduir/MCGA
cd MCGA

#We recommend using uv to set up the environment.
uv venv --python 3.10
source ./venv/bin/activate
uv pip install -r requirements.txt
```

## Download Modelã€Dataã€Inference
```
# å¯æ·»åŠ æ”¯æŒVLLMæ¡†æ¶çš„æ¨¡å‹ï¼Œä¾‹å¦‚ï¼š
# Qwen/Qwen2.5-Omni-7B  Qwen/Qwen3-Omni-30B-A3B-Instruct Qwen/Qwen2-Audio-7B-Instruct 
# mistralai/Voxtral-Small-24B-2507 mistralai/Voxtral-Mini-3B-2507 
# microsoft/Phi-4-multimodal-instruct

bash vllm_infer.sh \
    "mistralai/Voxtral-Mini-3B-2507" \
    "0" \
    8901 \
    "asr,s2tt,sec,sqa,su,sr" \
    "audio" \
    16 \
    "sk-your-openai-key-here"
```

| å‚æ•°ä½ç½® | å‚æ•°åç§° | è¯´æ˜ | ç¤ºä¾‹å€¼ |
| :--- | :--- | :--- | :--- |
| **`$1`** | **Model HF** | å¯æ·»åŠ æ”¯æŒVLLMæ¡†æ¶çš„æ¨¡å‹ï¼Œä¾‹å¦‚ï¼šï¼š<br>`Qwen/Qwen2.5-Omni-7B`, `Qwen/Qwen3-Omni-30B-A3B-Instruct`, `Qwen/Qwen2-Audio-7B-Instruct`<br>`mistralai/Voxtral-Small-24B-2507`, `mistralai/Voxtral-Mini-3B-2507`<br>`microsoft/Phi-4-multimodal-instruct` | `"Qwen/Qwen2.5-Omni-7B"` |
| **`$2`** | **GPUs** | æŒ‡å®šè¿è¡Œçš„ GPU ç¼–å· (æ”¯æŒå¤šå¡ï¼Œå¦‚ `"0,1"`) | `"0"` |
| **`$3`** | **Port** | vLLM æœåŠ¡ç›‘å¬çš„ç«¯å£å· | `8901` |
| **`$4`** | **Tasks** | è¯„æµ‹ä»»åŠ¡åˆ—è¡¨ï¼Œå¤šä¸ªä»»åŠ¡ç”¨é€—å·åˆ†éš” | `"asr,s2tt,sec,sqa,su,sr"` |
| **`$5`** | **Mode** | è¾“å…¥æ¨¡æ€é€‰æ‹©ï¼š`audio` (éŸ³é¢‘æ¨ç†) æˆ– `text` (çº¯æ–‡æœ¬) | `"audio"` |
| **`$6`** | **Workers** | å¹¶è¡Œå‘é€ API è¯·æ±‚çš„è¿›ç¨‹æ•°ï¼Œå»ºè®®æ ¹æ® CPU æ ¸æ•°è®¾ç½® | `16` |
| **`$7`** | **API Key** | å¯é€‰ã€‚ä»…åœ¨è°ƒç”¨ OpenAI æ¨¡å‹ï¼ˆå¦‚ GPT-4o-Audioï¼‰æ—¶éœ€è¦ | `"sk-xxxx"` |


<!-- ## Eval

```
cd eval
bash infer_model.sh
``` -->




## ğŸ–ŠCitation
```
@misc{du2026mcgamultitaskclassicalchinese,
      title={{MCGA}: A Multi-task Classical Chinese Literary Genre Audio Corpus}, 
      author={Yexing Du and Kaiyuan Liu and Bihe Zhang and Youcheng Pan and Bo Yang and Liangyu Huo and Xiyuan Zhang and Jian Xie and Daojing He and Yang Xiang and Ming Liu and Bin Qin},
      year={2026},
      eprint={2601.09270},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2601.09270}, 
}
```
